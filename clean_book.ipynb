{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dramatic-tragedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import spacy\n",
    "import re\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.gold import GoldParse\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "caroline-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list = []\n",
    "for i in range(1,18):\n",
    "    name = 'data/'+str(i)+'.txt'\n",
    "    damp = open(name).read().split('\\n')\n",
    "    #damp = [elem  for elem in damp if len(elem)>0]\n",
    "    big_list.extend(damp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "recreational-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16411"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list_2 = open(\"1.txt\").read().split('\\n')\n",
    "# list_2 = [elem  for elem in list_2 if len(elem)>0]\n",
    "# len(list_2)\n",
    "len(big_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imperial-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['CVE','CWE','SOFTWARE','MALWARE','COURSE_OF_ACTION',\n",
    "           'INTRUSION_SET','THREAT_ACTOR','TOOL','ATTACK_PATTERN','MITRE_ATTACK',\n",
    "            'INDUSTRY','TIMESTAMP','CAMPAIGN','ORG','COUNTRY','CITY',\n",
    "            'GEOLOCATION','IOC'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "identified-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_train2 = []\n",
    "for elem in big_list[:2000]:\n",
    "    if '(<' or '>)' in elem:\n",
    "        elem = elem.replace('(<','<')\n",
    "        elem = elem.replace('>)','>')\n",
    "    for tag in tag_list:\n",
    "        tag_start = '<' + tag +'>'\n",
    "        if tag_start in elem:\n",
    "            annotation = {}\n",
    "            end_tag = '</'+ tag + '>'\n",
    "            label_list = re.findall(tag_start+'(.*?)'+end_tag,elem)\n",
    "            if len(label_list) == 1:\n",
    "                pos_start = elem.find(label_list[0])\n",
    "                pos_end = elem.find(label_list[0]) + len(label_list[0])\n",
    "                ent_dict = {}\n",
    "                ent_dict['entities'] = [(pos_start+1,pos_end+1,tag)]\n",
    "                #elem = elem[0:pos_end] + ' ' + elem[pos_end:]\n",
    "                elem = elem[0:pos_start] +' ' +  label_list[0] + ' ' + elem[pos_end:]\n",
    "                spacy_sent = (elem,ent_dict)\n",
    "                spacy_train2.append(spacy_sent)\n",
    "               \n",
    "            else:\n",
    "                ent_dict = {}\n",
    "                ent_dict['entities'] = []\n",
    "                for mult_label in label_list:\n",
    "                        pos_start = elem.find(mult_label)\n",
    "                        pos_end = elem.find(mult_label) + len(mult_label)\n",
    "                        ent_dict['entities'].append((pos_start+1,pos_end+1,tag))\n",
    "                        #elem = elem[0:pos_end] + ' ' + elem[pos_end:]\n",
    "                        elem = elem[0:pos_start] +' ' +  mult_label + ' ' + elem[pos_end:]\n",
    "                spacy_train2.append((elem,ent_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "realistic-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinc_gpu_ops.AVAILABLE\n",
    "# spacy.prefer_gpu()\n",
    "nlp_test=spacy.blank(\"en\")\n",
    "nlp_test.add_pipe(nlp_test.create_pipe('ner'))\n",
    "nlp_test.begin_training()\n",
    "ner_test=nlp_test.get_pipe(\"ner\")\n",
    "TRAIN_DATA = spacy_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "aboriginal-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "      for ent in annotations.get(\"entities\"):\n",
    "        ner_test.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "competent-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "corporate-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vlad3d/opt/anaconda3/envs/TensorFlow2/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: [W030] Some entities could not be aligned in the text \"<SOFTWARE>  Java Script </SOFTWARE> objects were n...\" with entities \"[(11, 21, 'SOFTWARE')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/vlad3d/opt/anaconda3/envs/TensorFlow2/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: [W030] Some entities could not be aligned in the text \"<SOFTWARE>  Java  </SOFTWARE> Version <= 1.6.0_27 ...\" with entities \"[(11, 15, 'SOFTWARE')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/vlad3d/opt/anaconda3/envs/TensorFlow2/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: [W030] Some entities could not be aligned in the text \"product will be called <SOFTWARE>  JDK 8 u5 </SOFT...\" with entities \"[(34, 41, 'SOFTWARE')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/vlad3d/opt/anaconda3/envs/TensorFlow2/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: [W030] Some entities could not be aligned in the text \"<SOFTWARE>  Java  </SOFTWARE> is installed if eith...\" with entities \"[(11, 15, 'SOFTWARE')]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities (with BILUO tag '-') will be ignored during training.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "optimizer = nlp_test.resume_training()\n",
    "for itn in range(20):\n",
    "# shuffle examples before training\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    # ictionary to store losses\n",
    "    losses = {}\n",
    "    for text,ent in TRAIN_DATA:\n",
    "        content = text\n",
    "        annot = ent['entities']\n",
    "        #print(text,annot)\n",
    "        text = nlp_test.make_doc(content)\n",
    "        if len(annot) != 0:\n",
    "            cust_ann = [(annot[0][0],annot[0][1],annot[0][2])] \n",
    "            gold = GoldParse(text,entities = cust_ann)\n",
    "            nlp_test.update([text],[gold],sgd=optimizer,losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "gorgeous-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = open(\"test_3.txt\").read().split('\\n')\n",
    "#tester = [elem  for elem in tester  if len(elem)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "imported-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "teg_list = []\n",
    "for sent in tester:\n",
    "    doc = nlp_test(sent)\n",
    "    if len(doc.ents) != 0:\n",
    "        for elem in doc.ents:\n",
    "            teg_list.append((elem.text,elem.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "contained-excerpt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Emergency', 'SOFTWARE'),\n",
       " ('Report Table', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Emergency', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Remote Desktop Protocol)', 'MALWARE'),\n",
       " ('Operation Ghost', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('. Since', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Info of', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('2nd Comparison', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('winsec64 Decryption', 'SOFTWARE'),\n",
       " ('Time-', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Info of', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Info-', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Name Main', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('User', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Code of', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('/Dllbot.235520 2012.07.06.02', 'MITRE_ATTACK'),\n",
       " ('Security Trend', 'SOFTWARE'),\n",
       " ('Security Trend', 'SOFTWARE')]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "sonic-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('list_f4.pkl', 'wb') as fp:\n",
    "    pickle.dump(teg_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "robust-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('models/')\n",
    "nlp_test.to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "amateur-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from Dir models\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading from Dir\", output_dir)\n",
    "nlp_loaded = spacy.load(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "combined-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = open(\"test_4.txt\").read().split('\\n')\n",
    "preds = [elem  for elem in preds  if len(elem)>0]\n",
    "pred_list = []\n",
    "for sent in preds:\n",
    "    doc = nlp_loaded(sent)\n",
    "    if len(doc.ents) != 0:\n",
    "        for elem in doc.ents:\n",
    "            pred_list.append((elem.text,elem.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "enormous-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SPECIAL', 'SOFTWARE'),\n",
       " ('SPECIAL', 'SOFTWARE'),\n",
       " ('SPECIAL', 'SOFTWARE'),\n",
       " ('SPECIAL REPORT', 'SOFTWARE'),\n",
       " ('M-TRENDS 2020', 'TIMESTAMP')]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "prompt-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_test.vocab.vectors_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-modeling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
